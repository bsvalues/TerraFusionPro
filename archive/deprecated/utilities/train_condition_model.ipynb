{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TerraFusion Property Condition Model Training\n",
    "\n",
    "This notebook trains a model to predict property condition from images.\n",
    "The model will output a score from 1-5, where:\n",
    "- 1: Poor condition\n",
    "- 2: Fair condition\n",
    "- 3: Average condition\n",
    "- 4: Good condition\n",
    "- 5: Excellent condition\n",
    "\n",
    "We'll use a pre-trained MobileNetV2 model and fine-tune it for our classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define paths for datasets\n",
    "DATASET_DIR = \"dataset\"  # Main folder containing subfolders 1-5\n",
    "MODEL_SAVE_PATH = \"models/condition_model.pth\"  # Where to save the trained model\n",
    "\n",
    "# Set hyperparameters\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 5\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_CLASSES = 5  # Condition grades 1-5\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define image transformations for training\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Define image transformations for validation\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Custom dataset class for property condition images\n",
    "class PropertyConditionDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        \n",
    "        # Collect all image paths and labels\n",
    "        for condition in range(1, 6):  # Condition classes 1-5\n",
    "            condition_dir = os.path.join(root_dir, str(condition))\n",
    "            if os.path.exists(condition_dir):\n",
    "                for img_name in os.listdir(condition_dir):\n",
    "                    if img_name.lower().endswith(('.png', '.jpg', '.jpeg', '.webp')):\n",
    "                        img_path = os.path.join(condition_dir, img_name)\n",
    "                        # Labels are 0-4 (for condition grades 1-5)\n",
    "                        self.samples.append((img_path, condition - 1))\n",
    "        \n",
    "        # Check if we have samples\n",
    "        if len(self.samples) == 0:\n",
    "            print(f\"WARNING: No image samples found in {root_dir}\")\n",
    "            print(\"Please make sure you have images in the dataset/1, dataset/2, etc. folders\")\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        \n",
    "        try:\n",
    "            # Load and transform image\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            \n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "                \n",
    "            return image, label\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {str(e)}\")\n",
    "            # Return a fallback image and the same label\n",
    "            fallback = torch.zeros((3, 224, 224))\n",
    "            return fallback, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create datasets\n",
    "dataset = PropertyConditionDataset(DATASET_DIR, transform=train_transforms)\n",
    "\n",
    "# Calculate split sizes\n",
    "total_size = len(dataset)\n",
    "train_size = int(0.8 * total_size)  # 80% for training\n",
    "val_size = total_size - train_size  # 20% for validation\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Update transforms for validation set\n",
    "val_dataset.dataset.transform = val_transforms\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Total samples: {total_size}\")\n",
    "print(f\"Training samples: {train_size}\")\n",
    "print(f\"Validation samples: {val_size}\")\n",
    "\n",
    "# Count samples per class\n",
    "class_counts = [0] * NUM_CLASSES\n",
    "for _, label in dataset.samples:\n",
    "    class_counts[label] += 1\n",
    "    \n",
    "for condition, count in enumerate(class_counts, 1):\n",
    "    print(f\"Condition {condition}: {count} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load pre-trained MobileNetV2\n",
    "model = models.mobilenet_v2(pretrained=True)\n",
    "\n",
    "# Modify the classifier to output 5 classes\n",
    "num_features = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(num_features, NUM_CLASSES)\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n",
    "    # History for plotting\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_acc': []\n",
    "    }\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward + optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
    "        \n",
    "        history['train_loss'].append(epoch_loss)\n",
    "        history['train_acc'].append(epoch_acc.item())\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # Forward\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "        val_loss = running_loss / len(val_loader.dataset)\n",
    "        val_acc = running_corrects.double() / len(val_loader.dataset)\n",
    "        \n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc.item())\n",
    "        \n",
    "        # Print epoch stats\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print(f'Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "        print(f'Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
    "        print('-' * 40)\n",
    "        \n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            # Create directory if it doesn't exist\n",
    "            os.makedirs(os.path.dirname(MODEL_SAVE_PATH), exist_ok=True)\n",
    "            torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "            print(f\"Saved best model with accuracy: {val_acc:.4f}\")\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Before training, check if we have samples\n",
    "if len(dataset) > 0:\n",
    "    # Train the model\n",
    "    print(\"Starting training...\")\n",
    "    model, history = train_model(\n",
    "        model, \n",
    "        train_loader, \n",
    "        val_loader, \n",
    "        criterion, \n",
    "        optimizer, \n",
    "        NUM_EPOCHS, \n",
    "        device\n",
    "    )\n",
    "    print(\"Training complete!\")\n",
    "else:\n",
    "    print(\"No training samples found. Add images to dataset/1, dataset/2, etc. folders.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "if 'history' in locals():\n",
    "    # Plotting the training and validation loss\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_loss'], label='Training Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['train_acc'], label='Training Accuracy')\n",
    "    plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy over Epochs')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test the Model on Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def predict_condition(model, img_path, device):\n",
    "    # Load the image\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    \n",
    "    # Apply transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Get predictions\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(img_tensor)\n",
    "        probs = torch.nn.functional.softmax(outputs, dim=1)[0]\n",
    "        \n",
    "        # Get class prediction\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        condition_class = predicted.item() + 1  # Convert back to 1-5 scale\n",
    "        \n",
    "        # Calculate weighted average for a more precise score\n",
    "        weighted_score = 0\n",
    "        for i in range(5):\n",
    "            weighted_score += (i + 1) * probs[i].item()\n",
    "    \n",
    "    return condition_class, weighted_score, probs.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Test on a few validation samples if we have samples\n",
    "if len(val_dataset) > 0 and os.path.exists(MODEL_SAVE_PATH):\n",
    "    # Load the best saved model\n",
    "    model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "    model.eval()\n",
    "    \n",
    "    # Get a few samples\n",
    "    sample_indices = np.random.choice(len(val_dataset), min(5, len(val_dataset)), replace=False)\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        img_path, true_label = val_dataset.dataset.samples[val_dataset.indices[idx]]\n",
    "        true_label += 1  # Convert back to 1-5 scale\n",
    "        \n",
    "        # Predict\n",
    "        pred_class, weighted_score, probs = predict_condition(model, img_path, device)\n",
    "        \n",
    "        # Display image and predictions\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        plt.subplot(2, 3, i+1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"True: {true_label}, Pred: {pred_class}\\nScore: {weighted_score:.2f}\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Model saved to:\", os.path.abspath(MODEL_SAVE_PATH))\n",
    "else:\n",
    "    print(\"No model saved or no validation samples to test.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "To use this trained model in production:\n",
    "\n",
    "1. Gather a balanced dataset of property images labeled by condition (at least 20-30 images per class)\n",
    "2. Train the model using this notebook\n",
    "3. The model will be saved to `models/condition_model.pth`\n",
    "4. The `model_loader.py` script will automatically use this model for inference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}